### tensor.py

***** Imports *****
    - __future__
        - annotations
    - time, math, itertools, functools, struct, sys, inspect, pathlib, string, dataclasses, hashlib
    - contextlib
        - ContextDecorator
    - typing
        - List, Tuple, Callable, Optional, ClassVar, Type, Union, Sequence, cast, get_args, Literal, TYPE_CHECKING, SupportsIndex
    - tinygrad.dtype
        - DType, DTypeLike, dtypes, ImageDType, ConstType, least_upper_float, least_upper_dtype, sum_acc_dtype, to_dtype, truncate
    - tinygrad.helpers
        - argfix, make_tuple, flatten, prod, all_int, round_up, merge_dicts, argsort, getenv, all_same, fully_flatten, dedup
    - tinygrad.helpers
        - IMAGE, DEBUG, WINO, _METADATA, Metadata, TRACEMETA, ceildiv, fetch, polyN, unwra
    - tinygrad.multi
        - MultiLazyBuffer
    - tinygrad.gradient
        - compute_gradient
    - tinygrad.ops
        - smax, smin, resolve, UOp, Ops, sint, Variable, SimpleMathTrait, identity_element
    - tinygrad.device
        - Device, Buffer, BufferSpec
    - tinygrad.engine.realize
        - run_schedule
    - tinygrad.engine.memory
        - memory_planner
    - tinygrad.engine.schedule
        - ScheduleItem, create_schedule_with_vars
    - tinygrad.function as F


***** Classes and Functions *****
    *** Two base classes, Tensor and Function ***
    - class Function
        - def forward(*args, **kwargs)
        - def backward(*args, **kwargs)
        - def apply(fxn, *x, **kwargs)
    - def _metaop(op, shape, dtype, device, arg, src)
    - def _from_np_dtype(npdtype)
    - def _to_np_dtype(dtype)
    - def _fromnp(x)
    - def get_shape(x)
    - def _frompy(x, dtype)
    - def _get_winograd_matcols(mat, dims, shp, device, dtype)
    - def _apply_winograd_matrix(mat, t, dims)
    - def get_shape(x)
    - def _frompy(x, dtype)
    - def _get_winograd_matcols(mat, dims, shp, device, dtype)
    - def _apply_winograd_matrix(mat, t, dims)
    - def _align_left(*shapes)
    - def _broadcast_shape(*shapes)
    - def _masked_setitem(target, values, mask, axes)
    - const ReductionStr
    - class Tensor(SimpleMathTrait)
        - const __slots__
        - const __deletable__
        - const training
        - const no_grad
        - def __init__
        - def requires_grad_(requires_grad)
        - class train(ContextDecorator)
        - class test(ContextDecorator)
        - def __repr__
        - def __hash__
        - def __bool__
        - def __len__
        - def device
        - def shape
        - def dtype
        *** Data Handlers ***
        - def schedule_with_vars(*lst)
        - def schedule(*lst)
        - def realize(*lst, do_update_stats)
        - def replace(x)
        - def assign(x)
        - def detach
        - def _data
        - def data
        - def item
        - def tolist
        - def numpy
        - def clone
        - def to(device)
        - def to_(device)
        - def shard(devices, axis, splits)
        - def shard_(devices, axis, splits)
        - def from_uop(y, **kwargs)
        *** creation entrypoint ***
        - def _metaop(op, shape, device, dtype, arg, **kwargs)
        - def empty(*shpae, **kwargs)
        - def from_blob(ptr, shape, **kwargs)
        - def from_url(url, gunzip, **kwargs)
        - const _seed
        - const _device_seeds
        - const _device_rng_counters
        - def manual_seed(seed=0)
        - def _threefry_random_bits(key, counts0, counts1)
        - def rand(*shape, device, dtype, contiguous, **kwargs)
        *** Creation helper funcions ***
        - def full(shape, fill_value, **kwargs)
        - def zeros(*shape, **kwargs)
        - def ones(*shape, **kwargs)
        - def arange(start, stop, step, **kwargs)
        - def linspace(start, stop, steps, **kwargs)
        - def eye(n, m, **kwargs)
        - def full_like(fill_value, **kwargs)
        - def zeros_like(**kwargs)
        - def ones_like(**kwargs)
        - def rand_like(**kwargs)
        *** rng hlops ***
        - def randn(*shape, dtype, requires_grad, **kwargs)
        - def randint(*shape, low, high, dtype, **kwargs)
        - def normal(*shape, mean, std, requires_grad, **kwargs)
        - def uniform(*shape, low, high, dtype, requires_grad, **kwargs)
        - def scaled_uniform(*shape, **kwargs)
        - def glorot_uniform(*shape, **kwargs)
        - def kaiming_uniform(*shape, a, **kwargs)
        - def kaiming_normal(*shape, a, **kwargs)
        - def multinomial(num_samples, replacement)
        *** toposort and backward pass ***
        - def gradient(*targets, gradient)
        - def _deepwalk
        - def backward(gradient, retain_graph)
        *** movement low level ops ***
        - def view(*shape)
        - def reshape(shape, *args)
        - def expand(shape, *args)
        - def permute(order, *args)
        - def flip(axis, *args)
        - def shrink(arg)
        - def pad(padding, mode, value)
        *** movement high level ops ***
        - def _getitem(indices, v)
        - def __getitem__(indices)
        - def __setitem__(indices, v)
        - def gather(dim, index)
        - def cat(*args, dim)
        - def stack(*args, dim)
        - def repeat_interleave(repeats, dim)
        - def repeat(repeats, *args)
        - def _resolve_dim(dim, extra)
        - def split(sizes, dim)
        - def chunk(chunks, dim)
        - def meshgrid(*args, indexing)
        - def squeeze(dim)
        - def unsqueeze(dim)
        - def T
        - def transpose(dim0, dim1)
        - def flatten(start_diom, end_dim)
        - def unflatten(dim, sizes)
        - def roll(shifts, dims)
        *** Reduce ops ***
        - def _reduce(fxn, axis, keepdim)
        - def sum(axis, keepdim, acc_dtype)
        - def prod(axis, keepdim, acc_dtype)
        - def max(axis, keepdim)
        - def _inverse
        - def min(axis, keepdim)
        - def any(axis, keepdim)
        - def all(axis, keepdim)
        - def mean(axis, keepdim)
        - def var(axis, keepdim, correction)
        - def std(axis, keepdim, correction)
        - def mean(axis, keepdim)
        - def var(axis, keepdim, correction)
        - def std(axis, keepdim, correction)
        - def std_mean(axis, keepdim, correction)
        - def _softmax(axis, dtype)
        - def softmax(axis=-1, dtype)
        - def log_softmax(axis=-1, dtype)
        - def logsumexp(axis, keepdim)
        - def logcumsumexp(axis)
        - def argmax(axis, keepdim)
        - def argmin(axis, keepdim)
        - def rearrange(formula, **sizes)
            - def parse_formula(formula)
        - def einsum(formula, *operands, acc_dtype)
            - def parse_formula(formula, *operands)
        *** processing ops ***
        - def _pool(k_, stride, dilation)
        - def _padding2d(padding, dims)
        - def _ceil_mode_padding2d(k_, s_, d_, p_)
        - def avg_pool2d(kernel_size, stride, dilation, padding, ceil_mode, count_include_pad)
        - def max_pool2d(kernel_size, stride, dilation, padding, ceil_mode)
        - def conv2d(weight, bias, groups, stride, dilation, padding, acc_dtype)
        - def conv_transpose2d(weight, bias, groups, stride, dilation, padding, output_padding)
        - def dot(w, acc_dtype)
        - def matmul(x, reverse, acc_type)
        - def _cumalu(axis, op, _include_initial)
        - def _split_cumalu(axis, op)
        - def cumsum(axis)
        - def cummax(axis)
        - def _tri(r, c, diagonal, **kwargs)
        - def triu(diagonal)
        - def tril(diagonal)
        - def interpolate(size, mode, align_corners)
        - def scatter(dim, index, src, reduce)
        *** unary ops *** 
        - def logical_not
        - def neg
        - def contiguous
        - def log
        - def log2
        - def exp
        - def exp2
        - def relu
        - def sigmoid
        - def hardsigmoid(alpha, beta)
        - def sqrt
        - def rsqrt
        - def sin
        - def cos
        - def tan
        - def asin
        - def acos
        - def atan
        *** math functions ***
        - def trunc
        - def ceil
        - def floor
        - def round
        - def isinf(detect_positive, detect_negative)
        - def isnan
        - def lerp(end, weight)
        - def square
        - def clamp(min_, max_)
        - def clip(min_, max_)
        - def sign
        - def abs
        - def reciprocal
        *** activation functions ***
        - def elu(alpha=1.0)
        - def celu(alpha=1.0)
        - def selu(alpha, gamma)
        - def swish
        - def silu
        - def relu6
        - def hardswish
        - def tanh
        - def sinh
        - def cosh
        - def atanh
        - def sinh
        - def acosh
        - def hardtanh
        - def erf
        - def gelu
        - def quick_gelu
        - def leaky_gelu(neg_slope)
        - def mish
        - def softplus(beta)
        - def softsign
        *** broadcasted elementwise ops *** 
        - def _broadcast_to(new_shape)
        - def _broadcasted(y, reverse, match_dtype)
        - def _to_const_val(x)
        - def add(x, reverse)
        - def sub(x, reverse)
        - def mul(x, reverse)
        - def idiv(x, reverse)
        - def div(x, reverse)
        - def xor(x, reverse)
        - def bitwise_and(x, reverse)
        - def bitwise_or(x, reverse)
        - def bitwise_not
        - def lshift(x)
        - def rshift(x)
        - def pow(x, reverse)
        - def maximum(x)
        - def minimum(x)
        - def where(x, y)
        - def masked_fill(mask, value)
        *** op wrappers ***
        - def __invert__
        - def __lshift__(x)
        - def __rshift__(x)
        - def __pow__(x)
        - def __matmul__(x)
        - def __rpow__(x)
        - def __rmatmul__(x)
        - def __iadd__(x)
        - def __isub__(x)
        - def __imul__(x)
        - def __ipow__(x)
        - def __itruediv__(x)
        - def __ifloordiv__(x)
        - def __imatmul__(x)
        - def __iand__(x)
        - def __ior__(x)
        - def __ixor__(x)
        - def __ilshift__(x)
        - def __irshift__(x)
        - def __lt__(x)
        - def __gt__(x)
        - def __eq__(x)
        *** functional nn ops ***
        - def linear(weight, bias)
        - def sequential(ll)
        - def layernorm(axis, eps)
        - def batchnorm(weight, bias, mean, invstd, axis)
        - def dropout(p)
        - def _one_hot_along_dim(num_classes, dim)
        - def one_hot(num_classes)
        - def scaled_dot_product_attention(key, value, attn_mask, dropout_p, is_causal)
        - def _dp_reduction(reduction)
        - def binary_crossentropy(Y, reduction)
        - def binary_crossentropy_logits(Y, reduction)
        - def sparse_categorical_crossentropy(Y, ignore_index, label_smoothing, reduction)
        - def cross_entropy(Y, reduction, label_smooting)
        - def nll_loss(Y, weight, ignore_index, reduction)
        *** Tensor Properties ***
        - def ndim
        - def numel
        - def element_size
        - def nbytes
        - def is_floating_point
        - def size(dim)
        *** cast ops ***
        - def llvm_bf16_cast(dtype)
        - def cast(dtype)
        - def bitcast(dtype)
        - def float
        - def half
        - def int
        - def bool
        *** image tensor function replacements ***
        - def image_dot(w, acc_type)
        - def image_conv2d(weight, bias, groups, stride, dilation, padding, acc_dtype)
        - def _metadata_wrapper(fn)
            - def _wrapper(*args, **kwargs)